{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception Score.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwkZ7vNWzTGRjL86lBjJWP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGraceMaclean/GAN-Analysis/blob/master/Inception_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-AvvgmTR5m6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d05da554-fefc-44fb-ecfa-6aedc661ffc8"
      },
      "source": [
        "!git clone https://github.com/nnuyi/Inception-Score.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Inception-Score'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Total 63 (delta 0), reused 0 (delta 0), pack-reused 63\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfVgAaASwBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "9095922c-11b5-4c9f-c9e5-7c4b03af8d95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1PP0ygSmmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "45473188-3a7b-4d13-c535-e40cdf4f36c6"
      },
      "source": [
        "# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import scipy.misc\n",
        "import math\n",
        "import sys\n",
        "\n",
        "MODEL_DIR = '/tmp/imagenet'\n",
        "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
        "softmax = None\n",
        "\n",
        "# Call this function with list of images. Each of elements should be a \n",
        "# numpy array with values ranging from 0 to 255.\n",
        "def get_inception_score(images, splits=10):\n",
        "  assert(type(images) == list)\n",
        "  assert(type(images[0]) == np.ndarray)\n",
        "  assert(len(images[0].shape) == 3)\n",
        "  assert(np.max(images[0]) > 10)\n",
        "  assert(np.min(images[0]) >= 0.0)\n",
        "  inps = []\n",
        "  for img in images:\n",
        "    img = img.astype(np.float32)\n",
        "    inps.append(np.expand_dims(img, 0))\n",
        "  bs = 100\n",
        "  with tf.Session() as sess:\n",
        "    preds = []\n",
        "    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n",
        "    for i in range(n_batches):\n",
        "        sys.stdout.write(\".\")\n",
        "        sys.stdout.flush()\n",
        "        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n",
        "        inp = np.concatenate(inp, 0)\n",
        "        pred = sess.run(softmax, {'ExpandDims:0': inp})\n",
        "        preds.append(pred)\n",
        "    preds = np.concatenate(preds, 0)\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "      kl = np.mean(np.sum(kl, 1))\n",
        "      scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "# This function is called automatically.\n",
        "def _init_inception():\n",
        "  global softmax\n",
        "  if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "  filename = DATA_URL.split('/')[-1]\n",
        "  filepath = os.path.join(MODEL_DIR, filename)\n",
        "  if not os.path.exists(filepath):\n",
        "    def _progress(count, block_size, total_size):\n",
        "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
        "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "      sys.stdout.flush()\n",
        "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(filepath)\n",
        "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "  tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n",
        "  with tf.gfile.FastGFile(os.path.join(\n",
        "      MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    _ = tf.import_graph_def(graph_def, name='')\n",
        "  # Works with an arbitrary minibatch size.\n",
        "  with tf.Session() as sess:\n",
        "    pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n",
        "    ops = pool3.graph.get_operations()\n",
        "    for op_idx, op in enumerate(ops):\n",
        "        for o in op.outputs:\n",
        "            shape = o.get_shape()\n",
        "            shape = [s.value for s in shape]\n",
        "            new_shape = []\n",
        "            for j, s in enumerate(shape):\n",
        "                if s == 1 and j == 0:\n",
        "                    new_shape.append(None)\n",
        "                else:\n",
        "                    new_shape.append(s)\n",
        "            o._shape = tf.TensorShape(new_shape)\n",
        "    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\n",
        "    logits = tf.matmul(tf.squeeze(pool3), w)\n",
        "    softmax = tf.nn.softmax(logits)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    if softmax is None:\n",
        "      _init_inception()\n",
        "      \n",
        "    def get_images(filename):\n",
        "        return scipy.misc.imread(filename)\n",
        "        \n",
        "    filenames = glob.glob(os.path.join('./data', '*.*'))\n",
        "    images = [get_images(filename) for filename in filenames]\n",
        "    print(len(images))\n",
        "    print(get_inception_score(images))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            ">> Downloading inception-2015-12-05.tgz 100.0%\n",
            "Succesfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n",
            "WARNING:tensorflow:From <ipython-input-11-a7521b49822a>:71: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a7521b49822a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0m_init_inception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a7521b49822a>\u001b[0m in \u001b[0;36m_init_inception\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax/logits/MatMul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_shape\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     raise ValueError(\n\u001b[0;32m--> 508\u001b[0;31m         \"Tensor._shape cannot be assigned, use Tensor.set_shape instead.\")\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_when_autograph_disabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor._shape cannot be assigned, use Tensor.set_shape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYFIQ2jfToI-",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHflLgB_X0xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "6ffb87c9-1b25-4782-94e6-c84f0f5b82de"
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Inception-Score\n",
        "Code derived from https://github.com/openai/improved-gan/blob/master/inception_score/model.py and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "Usage:\n",
        "    Call get_inception_score(images, splits=10)\n",
        "Args:\n",
        "    images: A numpy array with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. A dtype of np.uint8 is recommended to save CPU memory.\n",
        "    splits: The number of splits of the images, default is 10.\n",
        "Returns:\n",
        "    Mean and standard deviation of the Inception Score across the splits.\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "tfgan = tf.contrib.gan\n",
        "\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 64\n",
        "INCEPTION_URL = 'http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz'\n",
        "INCEPTION_FROZEN_GRAPH = 'inceptionv1_for_inception_score.pb'\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None])\n",
        "def inception_logits(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    logits = tf.map_fn(\n",
        "        fn = functools.partial(\n",
        "             tfgan.eval.run_inception, \n",
        "             default_graph_def_fn = functools.partial(\n",
        "             tfgan.eval.get_graph_def_from_url_tarball, \n",
        "             INCEPTION_URL, \n",
        "             INCEPTION_FROZEN_GRAPH, \n",
        "             os.path.basename(INCEPTION_URL)), \n",
        "             output_tensor = 'logits:0'),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 8,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
        "    return logits\n",
        "\n",
        "logits=inception_logits()\n",
        "\n",
        "def get_inception_probs(inps):\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    preds = np.zeros([inps.shape[0], 1000], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        preds[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(logits,{inception_images: inp})[:, :1000]\n",
        "    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
        "    return preds\n",
        "\n",
        "def preds2score(preds, splits=10):\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "        kl = np.mean(np.sum(kl, 1))\n",
        "        scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "def get_inception_score(images, splits=10):\n",
        "    assert(type(images) == np.ndarray)\n",
        "    assert(len(images.shape) == 4)\n",
        "    assert(images.shape[1] == 3)\n",
        "    assert(np.min(images[0]) >= 0 and np.max(images[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    print('Calculating Inception Score with %i images in %i splits' % (images.shape[0], splits))\n",
        "    start_time=time.time()\n",
        "    preds = get_inception_probs(images)\n",
        "    mean, std = preds2score(preds, splits)\n",
        "    print('Inception Score calculation time: %f s' % (time.time() - start_time))\n",
        "    return mean, std  # Reference values: 11.38 for 50000 CIFAR-10 training set images, or mean=11.31, std=0.10 if in 10 splits."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-87739da03ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtfgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.contrib' has no attribute 'gan'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spj5qvvWYA50",
        "colab_type": "text"
      },
      "source": [
        "FID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnlEoJv_YEL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "11271713-7250-4b3a-8129-181f011eddac"
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Frechet-Inception-Distance\n",
        "Code derived from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "Usage:\n",
        "    Call get_fid(images1, images2)\n",
        "Args:\n",
        "    images1, images2: Numpy arrays with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. \n",
        "    dtype of the images is recommended to be np.uint8 to save CPU memory.\n",
        "Returns:\n",
        "    Frechet Inception Distance between the two image distributions.\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "tfgan = tf.contrib.gan\n",
        "\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None])\n",
        "activations1 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations1')\n",
        "activations2 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations2')\n",
        "fcd = tfgan.eval.frechet_classifier_distance_from_activations(activations1, activations2)\n",
        "\n",
        "def inception_activations(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    activations = tf.map_fn(\n",
        "        fn = functools.partial(tfgan.eval.run_inception, output_tensor = 'pool_3:0'),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 8,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    activations = array_ops.concat(array_ops.unstack(activations), 0)\n",
        "    return activations\n",
        "\n",
        "activations =inception_activations()\n",
        "\n",
        "def get_inception_activations(inps):\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        act[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(activations, feed_dict = {inception_images: inp})\n",
        "    return act\n",
        "\n",
        "def activations2distance(act1, act2):\n",
        "     return session.run(fcd, feed_dict = {activations1: act1, activations2: act2})\n",
        "        \n",
        "def get_fid(images1, images2):\n",
        "    assert(type(images1) == np.ndarray)\n",
        "    assert(len(images1.shape) == 4)\n",
        "    assert(images1.shape[1] == 3)\n",
        "    assert(np.min(images1[0]) >= 0 and np.max(images1[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(type(images2) == np.ndarray)\n",
        "    assert(len(images2.shape) == 4)\n",
        "    assert(images2.shape[1] == 3)\n",
        "    assert(np.min(images2[0]) >= 0 and np.max(images2[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(images1.shape == images2.shape), 'The two numpy arrays must have the same shape'\n",
        "    print('Calculating FID with %i images from each distribution' % (images1.shape[0]))\n",
        "    start_time = time.time()\n",
        "    act1 = get_inception_activations(images1)\n",
        "    act2 = get_inception_activations(images2)\n",
        "    fid = activations2distance(act1, act2)\n",
        "    print('FID calculation time: %f s' % (time.time() - start_time))\n",
        "    return fid"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6eb68919eb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtfgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.contrib' has no attribute 'gan'"
          ]
        }
      ]
    }
  ]
}