{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception Score.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIp2khTVaJoARPLY91BlpR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGraceMaclean/GAN-Analysis/blob/master/Inception_Score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHXsWnavBABi",
        "colab_type": "text"
      },
      "source": [
        "# Inception Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-AvvgmTR5m6",
        "colab_type": "code",
        "outputId": "0a864a97-46e5-420d-bbf6-4681b9eb8982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!git clone https://github.com/nnuyi/Inception-Score.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Inception-Score'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "Unpacking objects:   1% (1/63)   \rUnpacking objects:   3% (2/63)   \rUnpacking objects:   4% (3/63)   \rUnpacking objects:   6% (4/63)   \rUnpacking objects:   7% (5/63)   \rUnpacking objects:   9% (6/63)   \rUnpacking objects:  11% (7/63)   \rUnpacking objects:  12% (8/63)   \rUnpacking objects:  14% (9/63)   \rUnpacking objects:  15% (10/63)   \rUnpacking objects:  17% (11/63)   \rUnpacking objects:  19% (12/63)   \rUnpacking objects:  20% (13/63)   \rUnpacking objects:  22% (14/63)   \rUnpacking objects:  23% (15/63)   \rUnpacking objects:  25% (16/63)   \rUnpacking objects:  26% (17/63)   \rUnpacking objects:  28% (18/63)   \rUnpacking objects:  30% (19/63)   \rUnpacking objects:  31% (20/63)   \rUnpacking objects:  33% (21/63)   \rUnpacking objects:  34% (22/63)   \rUnpacking objects:  36% (23/63)   \rUnpacking objects:  38% (24/63)   \rUnpacking objects:  39% (25/63)   \rUnpacking objects:  41% (26/63)   \rremote: Total 63 (delta 0), reused 0 (delta 0), pack-reused 63\u001b[K\n",
            "Unpacking objects:  42% (27/63)   \rUnpacking objects:  44% (28/63)   \rUnpacking objects:  46% (29/63)   \rUnpacking objects:  47% (30/63)   \rUnpacking objects:  49% (31/63)   \rUnpacking objects:  50% (32/63)   \rUnpacking objects:  52% (33/63)   \rUnpacking objects:  53% (34/63)   \rUnpacking objects:  55% (35/63)   \rUnpacking objects:  57% (36/63)   \rUnpacking objects:  58% (37/63)   \rUnpacking objects:  60% (38/63)   \rUnpacking objects:  61% (39/63)   \rUnpacking objects:  63% (40/63)   \rUnpacking objects:  65% (41/63)   \rUnpacking objects:  66% (42/63)   \rUnpacking objects:  68% (43/63)   \rUnpacking objects:  69% (44/63)   \rUnpacking objects:  71% (45/63)   \rUnpacking objects:  73% (46/63)   \rUnpacking objects:  74% (47/63)   \rUnpacking objects:  76% (48/63)   \rUnpacking objects:  77% (49/63)   \rUnpacking objects:  79% (50/63)   \rUnpacking objects:  80% (51/63)   \rUnpacking objects:  82% (52/63)   \rUnpacking objects:  84% (53/63)   \rUnpacking objects:  85% (54/63)   \rUnpacking objects:  87% (55/63)   \rUnpacking objects:  88% (56/63)   \rUnpacking objects:  90% (57/63)   \rUnpacking objects:  92% (58/63)   \rUnpacking objects:  93% (59/63)   \rUnpacking objects:  95% (60/63)   \rUnpacking objects:  96% (61/63)   \rUnpacking objects:  98% (62/63)   \rUnpacking objects: 100% (63/63)   \rUnpacking objects: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfVgAaASwBt",
        "colab_type": "code",
        "outputId": "b1c56972-02bf-42fd-8eae-767507f22294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1PP0ygSmmf",
        "colab_type": "code",
        "outputId": "a04043c9-96fc-465a-aebe-14a1edca23bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os.path\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import scipy.misc\n",
        "import math\n",
        "import sys\n",
        "\n",
        "MODEL_DIR = '/tmp/imagenet'\n",
        "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
        "softmax = None\n",
        "\n",
        "# Call this function with list of images. Each of elements should be a \n",
        "# numpy array with values ranging from 0 to 255.\n",
        "def get_inception_score(images, splits=10):\n",
        "  assert(type(images) == list)\n",
        "  assert(type(images[0]) == np.ndarray)\n",
        "  assert(len(images[0].shape) == 3)\n",
        "  assert(np.max(images[0]) > 10)\n",
        "  assert(np.min(images[0]) >= 0.0)\n",
        "  inps = []\n",
        "  for img in images:\n",
        "    img = img.astype(np.float32)\n",
        "    inps.append(np.expand_dims(img, 0))\n",
        "  bs = 100\n",
        "  with tf.Session() as sess:\n",
        "    preds = []\n",
        "    n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n",
        "    for i in range(n_batches):\n",
        "        sys.stdout.write(\".\")\n",
        "        sys.stdout.flush()\n",
        "        inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n",
        "        inp = np.concatenate(inp, 0)\n",
        "        pred = sess.run(softmax, {'ExpandDims:0': inp})\n",
        "        preds.append(pred)\n",
        "    preds = np.concatenate(preds, 0)\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "      part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "      kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "      kl = np.mean(np.sum(kl, 1))\n",
        "      scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "# This function is called automatically.\n",
        "def _init_inception():\n",
        "  global softmax\n",
        "  if not os.path.exists(MODEL_DIR):\n",
        "    os.makedirs(MODEL_DIR)\n",
        "  filename = DATA_URL.split('/')[-1]\n",
        "  filepath = os.path.join(MODEL_DIR, filename)\n",
        "  if not os.path.exists(filepath):\n",
        "    def _progress(count, block_size, total_size):\n",
        "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
        "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "      sys.stdout.flush()\n",
        "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(filepath)\n",
        "    print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "  tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n",
        "  with tf.gfile.FastGFile(os.path.join(\n",
        "      MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    _ = tf.import_graph_def(graph_def, name='')\n",
        "  # Works with an arbitrary minibatch size.\n",
        "  with tf.Session() as sess:\n",
        "    pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n",
        "    ops = pool3.graph.get_operations()\n",
        "    for op_idx, op in enumerate(ops):\n",
        "        for o in op.outputs:\n",
        "            shape = o.get_shape()\n",
        "            shape = [s.value for s in shape]\n",
        "            new_shape = []\n",
        "            for j, s in enumerate(shape):\n",
        "                if s == 1 and j == 0:\n",
        "                    new_shape.append(None)\n",
        "                else:\n",
        "                    new_shape.append(s)\n",
        "            o._shape = tf.TensorShape(new_shape)\n",
        "    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\n",
        "    logits = tf.matmul(tf.squeeze(pool3), w)\n",
        "    softmax = tf.nn.softmax(logits)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    if softmax is None:\n",
        "      _init_inception()\n",
        "      \n",
        "    def get_images(filename):\n",
        "        return scipy.misc.imread(filename)\n",
        "        \n",
        "    filenames = glob.glob(os.path.join('./data', '*.*'))\n",
        "    images = [get_images(filename) for filename in filenames]\n",
        "    print(len(images))\n",
        "    print(get_inception_score(images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a7521b49822a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0m_init_inception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a7521b49822a>\u001b[0m in \u001b[0;36m_init_inception\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mnew_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax/logits/MatMul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_shape\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     raise ValueError(\n\u001b[0;32m--> 508\u001b[0;31m         \"Tensor._shape cannot be assigned, use Tensor.set_shape instead.\")\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_disallow_when_autograph_disabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor._shape cannot be assigned, use Tensor.set_shape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYFIQ2jfToI-",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqsgIazmbfv",
        "colab_type": "code",
        "outputId": "7db6f724-4fa8-445c-f67e-3fea7cd48f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.17.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y4PTr7HBPYW",
        "colab_type": "text"
      },
      "source": [
        "# **Inception Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHflLgB_X0xm",
        "colab_type": "code",
        "outputId": "fbdfecae-5587-4a3b-b7ac-78751da6789b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        }
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Inception-Score\n",
        "Code derived from https://github.com/openai/improved-gan/blob/master/inception_score/model.py and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "Usage:\n",
        "    Call get_inception_score(images, splits=10)\n",
        "Args:\n",
        "    images: A numpy array with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. A dtype of np.uint8 is recommended to save CPU memory.\n",
        "    splits: The number of splits of the images, default is 10.\n",
        "Returns:\n",
        "    Mean and standard deviation of the Inception Score across the splits.\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "tfgan = tf.contrib.gan\n",
        "\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 64\n",
        "INCEPTION_URL = 'http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz'\n",
        "INCEPTION_FROZEN_GRAPH = 'inceptionv1_for_inception_score.pb'\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None])\n",
        "def inception_logits(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    logits = tf.map_fn(\n",
        "        fn = functools.partial(\n",
        "             tfgan.eval.run_inception, \n",
        "             default_graph_def_fn = functools.partial(\n",
        "             tfgan.eval.get_graph_def_from_url_tarball, \n",
        "             INCEPTION_URL, \n",
        "             INCEPTION_FROZEN_GRAPH, \n",
        "             os.path.basename(INCEPTION_URL)), \n",
        "             output_tensor = 'logits:0'),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 8,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    logits = array_ops.concat(array_ops.unstack(logits), 0)\n",
        "    return logits\n",
        "\n",
        "logits=inception_logits()\n",
        "\n",
        "def get_inception_probs(inps):\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    preds = np.zeros([inps.shape[0], 1000], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        preds[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(logits,{inception_images: inp})[:, :1000]\n",
        "    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)\n",
        "    return preds\n",
        "\n",
        "def preds2score(preds, splits=10):\n",
        "    scores = []\n",
        "    for i in range(splits):\n",
        "        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n",
        "        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
        "        kl = np.mean(np.sum(kl, 1))\n",
        "        scores.append(np.exp(kl))\n",
        "    return np.mean(scores), np.std(scores)\n",
        "\n",
        "def get_inception_score(images, splits=10):\n",
        "    assert(type(images) == np.ndarray)\n",
        "    assert(len(images.shape) == 4)\n",
        "    assert(images.shape[1] == 3)\n",
        "    assert(np.min(images[0]) >= 0 and np.max(images[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    print('Calculating Inception Score with %i images in %i splits' % (images.shape[0], splits))\n",
        "    start_time=time.time()\n",
        "    preds = get_inception_probs(images)\n",
        "    mean, std = preds2score(preds, splits)\n",
        "    print('Inception Score calculation time: %f s' % (time.time() - start_time))\n",
        "    return mean, std  # Reference values: 11.38 for 50000 CIFAR-10 training set images, or mean=11.31, std=0.10 if in 10 splits."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            ">> Downloading http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz 100.0%WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spj5qvvWYA50",
        "colab_type": "text"
      },
      "source": [
        "# **FID**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrXYjoIVBwOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "1ff505a9-71a1-4905-a34e-48c6f7b08f82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP1-kdHWB5_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnlEoJv_YEL9",
        "colab_type": "code",
        "outputId": "35f1cbdd-b5c3-4110-e9b3-8fbd8282c7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "'''\n",
        "From https://github.com/tsc2017/Frechet-Inception-Distance\n",
        "Code derived from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py\n",
        "Usage:\n",
        "    Call get_fid(images1, images2)\n",
        "Args:\n",
        "    images1, images2: Numpy arrays with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. \n",
        "    dtype of the images is recommended to be np.uint8 to save CPU memory.\n",
        "Returns:\n",
        "    Frechet Inception Distance between the two image distributions.\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import functools\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.python.ops import array_ops\n",
        "tfgan = tf.contrib.gan\n",
        "\n",
        "session=tf.compat.v1.InteractiveSession()\n",
        "# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Run images through Inception.\n",
        "inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None])\n",
        "activations1 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations1')\n",
        "activations2 = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'activations2')\n",
        "fcd = tfgan.eval.frechet_classifier_distance_from_activations(activations1, activations2)\n",
        "\n",
        "def inception_activations(images = inception_images, num_splits = 1):\n",
        "    images = tf.transpose(images, [0, 2, 3, 1])\n",
        "    size = 299\n",
        "    images = tf.compat.v1.image.resize_bilinear(images, [size, size])\n",
        "    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)\n",
        "    activations = tf.map_fn(\n",
        "        fn = functools.partial(tfgan.eval.run_inception, output_tensor = 'pool_3:0'),\n",
        "        elems = array_ops.stack(generated_images_list),\n",
        "        parallel_iterations = 8,\n",
        "        back_prop = False,\n",
        "        swap_memory = True,\n",
        "        name = 'RunClassifier')\n",
        "    activations = array_ops.concat(array_ops.unstack(activations), 0)\n",
        "    return activations\n",
        "\n",
        "activations =inception_activations()\n",
        "\n",
        "def get_inception_activations(inps):\n",
        "    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))\n",
        "    act = np.zeros([inps.shape[0], 2048], dtype = np.float32)\n",
        "    for i in range(n_batches):\n",
        "        inp = inps[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] / 255. * 2 - 1\n",
        "        act[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(activations, feed_dict = {inception_images: inp})\n",
        "    return act\n",
        "\n",
        "def activations2distance(act1, act2):\n",
        "     return session.run(fcd, feed_dict = {activations1: act1, activations2: act2})\n",
        "        \n",
        "def get_fid(images1, images2):\n",
        "    assert(type(images1) == np.ndarray)\n",
        "    assert(len(images1.shape) == 4)\n",
        "    assert(images1.shape[1] == 3)\n",
        "    assert(np.min(images1[0]) >= 0 and np.max(images1[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(type(images2) == np.ndarray)\n",
        "    assert(len(images2.shape) == 4)\n",
        "    assert(images2.shape[1] == 3)\n",
        "    assert(np.min(images2[0]) >= 0 and np.max(images2[0]) > 10), 'Image values should be in the range [0, 255]'\n",
        "    assert(images1.shape == images2.shape), 'The two numpy arrays must have the same shape'\n",
        "    print('Calculating FID with %i images from each distribution' % (images1.shape[0]))\n",
        "    start_time = time.time()\n",
        "    act1 = get_inception_activations(images1)\n",
        "    act2 = get_inception_activations(images2)\n",
        "    fid = activations2distance(act1, act2)\n",
        "    print('FID calculation time: %f s' % (time.time() - start_time))\n",
        "    return fid\n",
        "\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:111: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            ">> Downloading http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz 100.0%WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAvphA8zBynZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = ['1_01_01.png', '1_01_02.png' , '1_01_03.png' , '1_01_04.png',\n",
        "    '1_02_01.png', '1_02_02.png' , '1_02_03.png' , '1_02_04.png',\n",
        "    '1_03_01.png', '1_03_02.png' , '1_03_03.png' , '1_03_04.png',\n",
        "    '1_04_01.png', \n",
        "    '2_01_01.png', '2_01_02.png' , '2_01_03.png' , '2_01_04.png',\n",
        "    '2_02_01.png', '2_02_02.png' , '2_02_03.png' , '2_02_04.png',\n",
        "    '2_03_01.png', '2_03_02.png' , '2_03_03.png' , '2_03_04.png',\n",
        "    '3_01_01.png', '3_01_02.png' , '3_01_03.png' , '3_01_04.png',\n",
        "    '3_02_01.png', '3_02_02.png' , '3_02_03.png' , '3_02_04.png',\n",
        "    '3_03_01.png', '3_03_02.png' , '3_03_03.png' , '3_03_04.png',\n",
        "    '3_04_01.png', \n",
        "    '4_01_01.png', '4_01_02.png' , '4_01_03.png' , '4_01_04.png',\n",
        "    '4_02_01.png', '4_02_02.png' , '4_02_03.png' , '4_02_04.png',\n",
        "    '4_03_01.png', '4_03_02.png' , '4_03_03.png' , '4_03_04.png'\n",
        "    ]\n",
        "\n",
        "b = ['1_01_01.png', '1_01_02.png' , '1_01_03.png' , '1_01_04.png',\n",
        "    '1_02_01.png', '1_02_02.png' , '1_02_03.png' , '1_02_04.png',\n",
        "    '1_03_01.png', '1_03_02.png' , '1_03_03.png' , '1_03_04.png',\n",
        "    '1_04_01.png', \n",
        "    '2_01_01.png', '2_01_02.png' , '2_01_03.png' , '2_01_04.png',\n",
        "    '2_02_01.png', '2_02_02.png' , '2_02_03.png' , '2_02_04.png',\n",
        "    '2_03_01.png', '2_03_02.png' , '2_03_03.png' , '2_03_04.png']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvRGNGYGIqVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = ['1_01_01.png', '1_01_02.png' , '1_01_03.png' , '1_01_04.png']\n",
        "b = ['1_01_01.png', '1_01_02.png' , '1_01_03.png' , '1_01_04.png']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGNE5rxqGPY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f16fc6df-63d3-4c8f-caf2-3aebd7fe8814"
      },
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "Original = []\n",
        "Predicted = []\n",
        "\n",
        "for x in a:\n",
        "      # load the image\n",
        "      image = Image.open('/content/drive/My Drive/Evaluation metrics SSIM/Real/'+x)\n",
        "      data = np.array(image)\n",
        "      data = data.transpose((-1, 0, 1))  \n",
        "      print(data)\n",
        "      Original.append(data)\n",
        "\n",
        "for xx in b:\n",
        "      # load the image\n",
        "      image = Image.open('/content/drive/My Drive/Evaluation metrics SSIM/Fake/'+xx)\n",
        "      data = np.array(image)\n",
        "      data = data.transpose((-1, 0, 1))\n",
        "      Predicted.append(data)\n",
        "\n",
        "\n",
        "\n",
        "Original = np.array(Original)\n",
        "Predicted = np.array(Predicted)\n",
        "\n",
        "print(type(Original))\n",
        "# summarize shape\n",
        "print(Original.shape)\n",
        "\n",
        "print(type(Predicted))\n",
        "# summarize shape\n",
        "print(Predicted.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0 120 ... 197 187 185]\n",
            "  ...\n",
            "  [  0   0 101 ... 154 150 144]\n",
            "  [  0   0 101 ... 154 150 144]\n",
            "  [  0   0 101 ... 150 153 148]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  80 ... 153 144 141]\n",
            "  ...\n",
            "  [  0   0  62 ... 101  98  93]\n",
            "  [  0   0  65 ...  99  96  90]\n",
            "  [  0   0  65 ...  96  99  96]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  58 ... 120 111 111]\n",
            "  ...\n",
            "  [  0   0  28 ...  56  58  53]\n",
            "  [  0   0  28 ...  56  56  52]\n",
            "  [  0   0  33 ...  52  58  56]]]\n",
            "[[[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  77 ... 148 145 145]\n",
            "  ...\n",
            "  [  0   0  71 ... 127 125 122]\n",
            "  [  0   0  71 ... 132 127 120]\n",
            "  [  0   0  73 ... 127 126 123]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  65 ... 104 102 104]\n",
            "  ...\n",
            "  [  0   0  52 ...  89  87  87]\n",
            "  [  0   0  50 ...  92  90  89]\n",
            "  [  0   0  52 ...  90  89  93]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  47 ...  47  50  53]\n",
            "  ...\n",
            "  [  0   0  22 ...  33  42  53]\n",
            "  [  0   0  24 ...  36  43  53]\n",
            "  [  0   0  24 ...  37  44  62]]]\n",
            "[[[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  98 ... 200 197 194]\n",
            "  ...\n",
            "  [  0   0 113 ... 208 208 208]\n",
            "  [  0   0 117 ... 208 212 211]\n",
            "  [  0   0 120 ... 215 215 209]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  71 ... 136 135 130]\n",
            "  ...\n",
            "  [  0   0  76 ... 138 141 142]\n",
            "  [  0   0  79 ... 138 147 145]\n",
            "  [  0   0  80 ... 148 148 142]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  39 ...  73  71  73]\n",
            "  ...\n",
            "  [  0   0  27 ...  71  71  74]\n",
            "  [  0   0  31 ...  70  77  79]\n",
            "  [  0   0  37 ...  79  82  76]]]\n",
            "[[[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0 160 ...  95  96  96]\n",
            "  ...\n",
            "  [  0   0 141 ...  85  86  85]\n",
            "  [  0   0 136 ...  83  83  89]\n",
            "  [  0   0 144 ...  85  83  87]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0 107 ...  61  64  64]\n",
            "  ...\n",
            "  [  0   0  92 ...  49  50  55]\n",
            "  [  0   0  87 ...  47  50  61]\n",
            "  [  0   0  92 ...  47  49  58]]\n",
            "\n",
            " [[  0   0   0 ...   0   0   0]\n",
            "  [  0   0   0 ...   0   0   0]\n",
            "  [  0   0  67 ...  27  30  30]\n",
            "  ...\n",
            "  [  0   0  46 ...  10  13  19]\n",
            "  [  0   0  43 ...  10  15  25]\n",
            "  [  0   0  50 ...  12  13  21]]]\n",
            "<class 'numpy.ndarray'>\n",
            "(4, 3, 66, 66)\n",
            "<class 'numpy.ndarray'>\n",
            "(4, 3, 66, 66)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7gm69paL-Wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bf9be9c3-5b47-44ea-cb65-e8d8be5d87a0"
      },
      "source": [
        "print(get_fid(Original, Predicted))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating FID with 4 images from each distribution\n",
            "FID calculation time: 24.771609 s\n",
            "127.25188\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}